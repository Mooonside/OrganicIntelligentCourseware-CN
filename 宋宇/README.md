个人信息
===
姓名：宋宇

学号：21821307

主题：复杂网络（Complex Networks）

论文选择
===

[Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/pdf/1603.08155.pdf)
ABSTRACT：
We consider image transformation problems, where an inputimage  is  transformed  into  an  output  image.  Recent  methods  for  suchproblems typically train feed-forward convolutional neural networks us-ing aper-pixelloss between the output and ground-truth images. Parallelwork has shown that high-quality images can be generated by definingand optimizingperceptualloss functions based on high-level features ex-tracted from pretrained networks. We combine the benefits of both ap-proaches, and propose the use of perceptual loss functions for trainingfeed-forward networks for image transformation tasks. We show resultson image style transfer, where a feed-forward network is trained to solvethe  optimization  problem  proposed  by  Gatyset  alin  real-time.  Com-pared to the optimization-based method, our network gives similar qual-itative results but is three orders of magnitude faster. We also experimentwith single-image super-resolution, where replacing a per-pixel loss witha perceptual loss gives visually pleasing results


摘要：

我们考虑图像转换问题，其中inputimage被转换为输出图像。用于这种问题的最新方法通常使用输出和地面实况图像之间的aper-pixel loss来训练前馈卷积神经网络。并行工作表明，通过基于从预训练网络中提取的高级特征来定义和优化感知功能，可以生成高质量的图像。我们结合了两种方法的优点，并提出使用感知损失函数来训练前馈网络进行图像转换任务。我们在图像样式转换中显示结果，其中训练前馈网络以实时解决Gatyset alin提出的优化问题。与基于优化的方法相比，我们的网络提供了类似的定性结果，但速度提高了三个数量级。我们还尝试使用单图像超分辨率，其中用感知损失替换每像素损失给出视觉上令人愉悦的结果。

![](https://i.imgur.com/irI8v3E.png)
如图所示，我们的系统分为两部分：一个图片转换网络和一个用来定义loss函数()的loss网络。图片转换网络是一个深度残差卷积神经网络，它的权值参数是 ，它利用映射来将输入图像转换成输出图像。loss 网络是训练好的图像分类网络（VGG），它定义了perceptual损失函数，该函数描述图片之间内容和风格的差距。loss网络在整个训练过程中参数保持不变。每个loss函数都计算出一个标量值，该值衡量输出图像与目标图像的差距。图片转换网络使用随机梯度下降的方式来最小化总loss函数。这个总loss函数是各个loss函数的带权合并，如公式 1：

![](https://i.imgur.com/lUJFtYV.png)


loss 网络定义特征重建loss以及风格重建loss，分别衡量图片内容与风格上的差异。对于特定的输入图像，我们有content target 和style target 。对于风格转换部分，content target 就是输入，style target 就是输入的风格图像。输出的图像应该具有的内容与的风格。
3.1 图像转换网络
 本文的图像转换网络使用[[[] Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434 (2015)]]提出的网络，不使用池化层，而使用一种新型卷积方式（strided convolutions）和反卷积在网络中进行上采样和下采样。我们的网络体由[[[] Gross, S., Wilber, M.: Training and investigating residual nets. http://torch.ch/blog/2016/02/04/resnets.html (2016)]]用到的5个残差块组成，所有的非残差卷积层之后都进行空间批处理标准化以及ReLU激活函数以保证图像的像素值在[0,255]之间。除了第一层和最后一层使用9x9的卷积核之外，其他卷积层都使用3x3的卷积核。

输入与输出：训练时，对于风格转换的输入和输出都是3的彩色图像。对于上采样因子为的超分辨率，输出是一个高分辨率的图像3，输入是低分辨率图像。因为图像转换网络是全卷积的，在测试的时候可以使用任何分辨率图像作为输入。

上采样和下采样：对于上采样因子为的超分辨率，我们在个1/2步长的卷积层之后使用残差块。对于图像转换网络，我们在残差块之后使用两个步长为2的卷积层用来对输入下采样然后再使用两个1/2步长的卷积层来上采样。

残差连接: 文献[[[] He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. arXiv preprint arXiv:1512.03385 (2015)]]提出使用残差连接训练深度网络对图像进行分类，提出残差连接可以使网络轻易地具有识别功能。所以我们的网络体由几个残差块组成，每个残差块包含3x3的卷积层。我们使用[14]中的残差块设计。


我们尽可能地生成与原图像相似的特征表示，该特征表示使用loss网络提取出来(本文中的loss网络是VGG16)。我们使用来表示loss网络的输入是时的第j层网络激活层。如果j是一个卷积层，那么是一个shape为的特征图。那么特征重建loss就是特征表示的欧氏距离：

![](https://i.imgur.com/KSN4SMA.png)


风格重建loss：特征重建loss得到的是图像的内容，而丢失了图像的颜色和细节等。这些都是由风格图像提供的，所以我们也需要得到它们。我们定义Gram 矩阵为的矩阵：
![](https://i.imgur.com/IdyqfFW.png)




我们可以将重构成一个的矩阵，那么风格重建loss等于输出与目标破图像的Gram矩阵的差值的Frobenius范数的平方。即：
![](https://i.imgur.com/dJNlIHt.png)



当我们最小化风格重建loss的时候，几层指定的网络输出的结果保留了目标图像的风格特征而丢失了空间结构。越深的网络层次提取到越大尺度的特征。为了从多层网络J中进行风格重建，我们定义为多层网络生成loss的总和，其中。

在配置好实验环境之后，我们需要准备一个风格图像，在本实验中，我们准备如下图所示的风格图像。

![](https://i.imgur.com/9pPFqFV.png)

然后我们运行train.py对模型进行训练，在训练的过程中，我们可以使用tensorboard来查看训练进程。


从图中我们可以看到，我们训练出来的模型效果很好，图片迁移转换后的图片和风格图片的风格几乎是一模一样。
![](https://i.imgur.com/VYzWQ3q.jpg)